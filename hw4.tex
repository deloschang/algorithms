%        File: hw2.tex
%     Created: Sun Oct 2 05:00 PM 2013 E
% Last Change: Sun Oct 2 05:00 PM 2013 E
%
\documentclass[a4paper]{report}

\title{HW 4}
\author{Delos Chang}
\date{}

\usepackage{amsmath, amsthm, amssymb, fancyhdr, tikz, algorithmicx, algpseudocode, algorithm}
\usepackage{mathtools}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\usetikzlibrary{arrows}
\newcommand{\justif}[2]{&{#1}&\text{#2}}
\renewcommand{\algorithmicforall}{\textbf{for each}}

\pagestyle{fancy}
\rhead{HW 4:  Delos Chang (help from Prof.)}
\begin{document}
  \begin{enumerate}
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 1 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \item 

      Guess: $O(\log(\log(n))$

      First, consider the equation without an inequality, i.e.: $T(n) = \sqrt{n} \cdot T(\sqrt{n}) + n$.

      In the recurrence tree, at the top level (level 0), the sum is $n$ (the root). At level 1, before expanding, there are
      $\sqrt{n}$ branches of $T(\sqrt{n})$.

      Expanding level 1, each $T(\sqrt{n})$ expands into $\sqrt{n}$ with branches $T(n^{1/4})$. In the expanded
      level 1, there are values $\sqrt{n}$ occurring $\sqrt{n}$ times. Therefore, the sum of the first level is also $n$.

      If we expand the second and third level, under each $\sqrt{n}$ in the first level, there are values $n^{1/4}$ occuring $n^{1/4}$ times.
      Thus, the expanded nodes would sum to $n^{1/2}$ in each subtree on the second level. There are $n^{1/2}$ occurrences of such values,
      thus the sum of the second level is also $n$.

      We see that the sum of level 0 is $n$, sum of level 1 is $n$ and sum of level 2 is $n$. Hence, we guess that at each level, the sum of each level will be $n$. 

      Now we analyze how many levels there will be in the recurrence tree. 

      At level 1, the quantity of nodes is $n^{\frac{1}{2}}$.
      At level 2, the quantity of nodes is $n^{\frac{1}{2^{2}}}$.

      Thus, at level $k$, the quantity of nodes would be $n^{\frac{1}{2^k}}$.

      Let $k$ be the point before $n^{\frac{1}{2^k}}$ becomes less than or equal to 2 (some constant):

      $$n^{\frac{1}{2^k}} \leq 2 $$

      $$\frac{1}{2^k} \log n \leq 1 $$

      $$ \log n \leq 2^{k} $$

      $$ \log(\log n) \leq k $$

      Therefore, there are $\log(\log n)$ levels. Each level contributes a sum of $n$. 

      Thus, we guess the tree to sum to $n \log(\log n)$ if $T(n) = \sqrt{n} \cdot T(\sqrt{n}) + n$.

      Since $T(n) < \sqrt{n} \cdot T(\sqrt{n}) + n$, then $T(n)$ also be less than the sum $n \log(\log n)$. 

      Hence, we guess $O(\log(\log(n)))$.


      %n top level,  rt n amont of T(\sqrt{n})
      %\sqrt n num of val \sqrt n
      %third level: n^1/4 branches with val n^1/4.     n^1/2 such subtrees

      %n^ 1/2^k \leq 2  levels



    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 2 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \par
    \bigskip

    \item 
      {\bf Overview:}

      1. Given graph G=(V,E), run SCC(G), as defined in class, 
      forming the component graph $G^{SCC} = (V^{SCC}, E^{SCC})$, a DAG. 

      2. Let $k$ denote the number of vertices in $V^{SCC}$. Run topological sort on the component graph $G^{SCC}$, 
      which will produce a linear order of vertices $V_{chain} = \{v_{0}, v_{1}, v_{2} \dots v_{k}\}$. 

      3. Check that this linear ordering of vertices is a chain. 
      In other words, check that from $i=0$ to $i=k-1$, $v_{i},v_{i+1} \in V_{chain}$ (assuming $v_{0}$ is the first vertex
      , the edge $(v_{i},v_{i+1}) \in E^{SCC}$.
      Note that $V_{chain}$ is not necessarily a linearly ordered chain.

      If edges $(v_{0}, v_{1}), (v_{1},v_{2}),\dots,(v_{k-1},v_{k}) \in E^{SCC}$, then $G$ is a semi-connected graph.
      If any of the aforementioned edges do not exist in $E^{SCC}$, then $G$ is not a semi-connected graph. 

      {\bf Pseudocode:}

      \begin{algorithmic}[1]
        \Function{SemiConnected}{$G(V,E)$}

        \State $G^{SCC}(V^{SCC},E^{SCC})$ = SCC($G=(V,E)$)
        \Comment Form component graph $G^{SCC}$

        \State $V_{chain}$ = TopSort($G^{SCC}$)
        \Comment $V_{chain}$ contains list returned by top sort

        \State $i=0$
        \Comment Check $V_{chain}$ if it contains linearly chained edges
        \While{$i < |V_{chain}|$}
          \If {$(v_{i},v_{i+1}) \not\in E^{SCC}$}
            \State return false
          \EndIf
          \State i++

        \EndWhile
        \State return true
      \EndFunction
    \end{algorithmic}

      {\bf Correctness:}
      All vertices in each strongly connected component are mutually reachable. 
      Thus, by definition, for all pairs of vertices $u$,$v$ in each strongly connected component graph, $u \leadsto v$ and $v \leadsto u$. 
      In other words, strongly connected components are semi-connected graphs. 
      These mutually reachable vertices are represented as one vertex in $V^{SCC}$. 

      Hence, if $G^{SCC}$ is semi-connected, then $G$ is semi-connected. 
      
      Let a linearly ordered chain be a set of vertices such that in $V_{chain}$ with $k$ SCCs, the
      edges $(v_{0}, v_{1}), (v_{1},v_{2}),\dots,(v_{k-1},v_{k}) \in E^{SCC}$.

      {\it Claim 1:} If there is a linearly ordered chain in $G^{SCC}$, $TopSort(G^{SCC})$ returns the linearly ordered chain. 

      A topological sort returns a linear ordering of all its vertices such that if $G$ contains an edge $(u,v)$, then $u$
      appears before $v$ in the ordering. Hence, it is vacuously true that because topological sort outputs vertices with respect 
      to its order in the edges, topological sort must return a linearly ordered chain if there is one. 

      {\it Claim 2:} $G^{SCC}$ is semi-connected iff $V_{chain}$ is a linearly ordered chain. 

      {\it Subclaim 1:} $G^{SCC}$ is semi-connected if $V_{chain}$ is a linearly ordered chain. 

      Consider $G^{SCC}=(V^{SCC}, E^{SCC})$ and that $V_{chain}$ is a linearly ordered chain generated by the topological sort on $G^{SCC}$. 

      Hence, between any two arbitrary vertices $u$,$v \in V^{SCC}$, either $u$ is a vertex before $v$ in the linearly ordered chain $V_{chain}$ or
      $v$ is a vertex before $u$. In the former case, $u \leadsto v$ through some chain of edges found by following the edges in 
      $V_{chain}$. In the latter case $v \leadsto u$ through some chain of edges. 

      Thus, because $u$ and $v$ can be arbitrary vertices in $V^{SCC}$, $G^{SCC}$ is semi-connected. 


      {\it Subclaim 2:} $G^{SCC}$ is not semi-connected if $V_{chain}$ is not a linearly ordered chain. 

      Consider $V_{chain}$ is not a linearly ordered chain. Then some two consecutive vertices $v_{i}$ and 
      $v_{i+1} \in V_{chain}$ but $(v_{i}, v_{i+1}) \not\in E^{SCC}$. 

      Either $v_{i}$ has outgoing edges or it doesn't. If $v_{i}$ has no outgoing edges, then there cannot be any path from
      $v_{i}$ to $v_{i+1}$, by definition. 

      If $v_{i}$ has outgoing edges, because of the property of topological sort in producing a linear ordering, edges from $v_{i}$ to 
      $v_{n}$ where $n > i+1$. Because each vertex $\in V^{SCC}$, no two vertices in $V^{SCC}$ are mutually reachable. Otherwise, 
      they would not be the maximal set, by definition of SCC. Furthermore, because of the linear ordering of topological sort, 
      there can be no path from any $v_{n}$ to $v_{i+1}$ ($v_{i+1}$ precedes $v_{n}$). 
      
      Hence, there can be no path from $v_{i}$ to $v_{i+1}$.

      Now, we show that no paths exist from $v_{i+1}$ to $v_{i}$.
      Because $v_{i}$ precedes $v_{i+1}$ and no two vertices in $V^{SCC}$ are mutually reachable (otherwise they would be in the same
      SCC), by top sort, there can be no paths from $v_{i+1}$ to $v_{i}$. 

      Hence, we have Subclaim 2 because no path exists from $v_{i+1}$ to $v_{i}$ or $v_{i}$ to $v_{i+1}$. 

      With Subclaim 1 and Subclaim 2, we have Claim 2. 


      {\bf Time Complexity:}
      
      Running SCC using DFS on $G$, then DFS on $G^{T}$ (transpose graph) as defined in class takes $\Theta(V+E)$.
      Forming the component graph takes $O(V+E)$. 
      Running Topological Sort on $G^{SCC}$ with DFS in reducing finishing times as defined in class takes $O(V+E)$ because.
      $G^{SCC}$ has at most $|V|$ vertices and $|E|$ edges. 
      To check the linearly ordered chain, the algorithm will check each vertex $v_{i}$ in $G^{SCC}$'s adjacency list to check for
      $(v_{i}, v_{i+1})$. Thus, the adjacency list is checked exactly once. Thus, $O(V+E)$.

      Hence, the time complexity of this algorithm is $\Theta(V+E)$.


    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 3 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \par
    \pagebreak
    \bigskip
    \setcounter{equation}{0}

    \item
      We modify the Mergesort algorithm on page 31 and 34.
      
      Given an array $A$ of ints size $n$, initialize the following pseudocode with $inversions(A, n)$: 

      {\bf Pseudocode:}
      \begin{algorithmic}[1]
        \Function{inversions}{$A, n$}
          \State $count = countInv(A, 1, n)$
          \State return $count$
        \EndFunction
      \end{algorithmic}

      {\it Pre-Condition:}

       - $n \geq 1$

      {\it Post-Condition:}

        - $count$ is the number of inversions in  $A[1 \dots n]$

        - $A[1\dots n]$ is a sorted permutation of the original array, $A'[1\dots n]$.

      {\bf Pseudocode:}
      \begin{algorithmic}[1]
        \Function{countInv}{$A, p, r$}
          \State $count = 0$
          \If {$p < r$}
            \State $q = \floor{(p+r) / 2}$
            \State $count +=$ countInv($A, p, q$)
            \State $count +=$ countInv($A, (q+1), r$)
            \State $count +=$ main($A, p, q, r$)
          \EndIf
          \State return $count$
        \EndFunction
      \end{algorithmic}

      {\it Pre-Condition:}

       - $p \leq r$

      {\it Post-Condition:}

        - $A[p\dots r]$ is a sorted permutation of the original array, $A'[p \dots r]$

        - for all $(m < p) \wedge (m > r), A[m] = A'[m]$

        - $count$ is the number of inversions in the {\it new} sorted permutation $A[p \dots r]$

      



      {\bf Pseudocode:}
      \begin{algorithmic}[1]
        \Function{main}{$A, p:$ first index of 1st seg, $q$:ending index of 1st seg, $r$:ending index of 2nd seg}
          \State $n_{1} = q - p + 1$
          \Comment Checking length of subarrays
          \State $n_{2} = r - q$
          \State let $L[1\dots n_{1} + 1]$ and $R[1\dots n_2 + 1]$ be new arrays
          \ForAll{$i = 1$ to $n_1$}
            \State $L[i]  = A[p + i - 1]$
          \EndFor
          \ForAll{$j = 1$ to $n_2$}
            \State $R[j] = A[q + j]$
          \EndFor

          \Comment add sentinel to know when to stop
          \State $L[n_1 + 1] = \infty$
          \State $R[n_2 + 1] = \infty$

          \State $i = 1$
          \State $j = 1$

          \State $checked = false$
          \State $count = 0$

          \ForAll{$k = p$ to $r$}
            \If {$L[i] > R[j] $ and $checked = false$}
              \State $checked = true$
              \State $count += n_1 - i + 1$
            \EndIf

            \If {$L[i] \leq R[j]$}
              \State $A[k] = L[i]$
              \State $i++$
            \Else 
              \State $A[k] = R[j]$
              \State $j++$
              \State $checked = false$
            \EndIf
          \EndFor
          \State return count
        \EndFunction
      \end{algorithmic}

      {\it Pre-Condition:}

        - $p \leq q \leq r \wedge$ $A[p\dots q]$ is sorted $\wedge$ $A[q+1\dots r]$ is sorted 

      {\it Post-Condition:}

        - $A[p\dots r]$ is a sorted permutation of $A'[p \dots r]$

        - for all $(m < p) \wedge (m > r), A[m] = A'[m]$

        - $count$ is the number of inversions in the {\it new} sorted permutation $A[p \dots r]$



      
     {\bf Time Complexity}
      
        - Merge sort's time complexity is $\Theta(n \cdot log n)$. To modify the original Merge Sort, we added lines that only
        take constant amount of time (assignments and constant time if statement checks):

        - In $countInv$, the initializations and assignments of $count$ take $\Theta(1)$ time.

        - Assignment on line (15) and (16) of $main$ take $\Theta(1)$ time.

        - on lines (18) - (21) of $main$, the $if$ statement checks for an inversion. The checks and assignments take $\Theta(1)$.

        Hence, the time complexity for this algorithm is the same as merge sort: $\Theta(n \cdot log n)$.
        





    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 4 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \par
    \bigskip
    \pagebreak
    \setcounter{equation}{0}
    
    \item 





    
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 5 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \bigskip
    \setcounter{equation}{0}
    \item 
      {\bf Optimal Substructure}

      Given the directed acyclic graph $G = (V,E)$, let $u$ be an arbitrary vertex in the graph $G$.

      Let $s$ be the source vertex and $t$ be the target vertex as defined by the problem.

      Given the edge $(u,v)$, let $weight(u,v)$ denote the real-valued edge weights of $(u,v)$.

      To find the longest weighted simple path from $s$ to $t$, there are two cases:
      
      1. If $u = t$, then it is vacuously true that $weight(u,t) = 0$.

      2. If $u \neq t$, then the longest weighted simple path can be found by taking the largest sum of
      (a) a weighted edge $weight(u,v)$ and (b) weight of the longest path from second vertex $v$ to $t$.
      
      To show \#2, let $x$ be the longest path from $u$ to $t$, given that $u \neq t$. Let $v$ be the 
      second vertex on path $x$. Let $x'$ be the path from $v$ to $t$.

      {\it Claim 1: $x'$ must be a longest path from $v$ to $t$}

      We show this by proof by contradiction. We assume that $x$ (the path from $u$ to $t$ is the longest path). 

      Also assume that a longer path $p$ exists from $v$ to $t$. We can form a path $u \rightarrow v$ then from 
      $v$ to $t$ through path $p$. However, because $G$ is acyclic, this path is longer than 
      $x$ because $p$ is longer than $x'$ (and $u \rightarrow v$ remains the same).
      
      Hence, we have a contradiction and proven Claim 1. 



      {\bf Appropriate Notation}

      Given the edge $(u,v)$, let $weight(u,v)$ denote the real-valued edge weights of $(u,v)$.

      Let $length[u]$ be the weight of a longest path from the source vertex $u$ to target vertex $t$.


      {\bf Recurrence with base cases}

      With the notation above and Claim 1, we can write the following recurrence: 

      \begin{displaymath}
        length[u] = \left\{
          \begin{array}{lr}
            0  &   \text{ if $u == t$}\\
            \text{$max_{(u,v)\in E}$( (length[v] + weight(u,v)))}  &  \text{ if $u \neq t$ }
          \end{array}
          \right.
        \end{displaymath} 



      {\bf Pseudocode: Optimal Value of Objective Function}

      {\it Overview:}

      We first topologically sort the vertices then solve in topological order from $s$ to $t$ bottom-up.

      $s$ is the source vertex. $t$ is the target vertex. 

      We use the $length$ array to memoize the results of our objective function subproblems.

      We use the $move$ array, we reconstruct the solution for printing.

      \begin{algorithmic}[1]
        \Function{calcLength}{$G(V,E)$, $s$, $t$}
          \State Topologically sort $G$
          \ForAll{$j=1$ to $|V|$}
            \State $length[j] = -\infty$
          \EndFor

          \State $length[s] = 0$
          \ForAll{ $u$ in topological order from $s$}
            \ForAll{$(u,v) \in E$}
              \If {$weight(u,v) + length[u] > length[v]$}
                \Comment Found better weighted longest path
                \State $move[u] = v$
                \State $length[v] = length[u] + weight(u,v)$
              \EndIf
            \EndFor
          \EndFor
          \State return $length[t]$
        \EndFunction
      \end{algorithmic}

      {\it Time and Space Complexity:}

      The algorithm runs in $\Theta(V+E)$ time. The topological sort takes $\Theta(V+E)$ time. We look through each of the
      edges in the adjacency list for vertices in the topological sort from $s$ to $t$. 

      The space complexity will be $\Theta(V)$ because we use two arrays that take up $V$ space (for each vertex, there is
      a position). 

      {\bf Pseudocode: Optimal Solution}

      {\it Overview:}
      Given the data stored in the $move$ array, we can reconstruct the solution

      \begin{algorithmic}[1]
        \Function{printSimplePath}{$move$, $s$, $t$}
          \State print $s$
          \State $v = move[s]$
          \While{ $v \neq t$}
            \State print $v$
            \State $v = move[v]$
          \EndWhile
        \EndFunction
      \end{algorithmic}

      {\it Time and Space Complexity:}

      $move$ array will hold the vertices on the longest path, according to $calcLength$. 
      The longest path holds at least 2 vertices and at most $|V|$ vertices. Thus, the time complexity of this algorithm $\Theta(V)$.

      $printSimplePath$ does not add any more space to the complexity of the algorithm because $move$, $s$ and $t$ are already
      defined. Thus, the entire algorithm's ($printSimplePath$ and $calcLength$) space complexity is still $\Theta(V)$.

    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 6 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \pagebreak
    \bigskip
    \setcounter{equation}{0}
    \item 
      {\bf Optimal Substructure}

      Let $W[1\dots j]$ denote the sequence of characters in an arbitrary input string. Let $V[1\dots k]$
      be a longest palindrome subsequence (LPS) of $W[1\dots j]$. 

      Consider the following cases:

      1. If $j=1$, then $k=1$ and $W[1] = V[1]$. For example, a LPS of ``a'' is ``a''.

      2. If $j=2$ and $W[1] = W[2]$, then $k=2$ and $W[1] = V[1] = W[2] = V[2]$. For example, a LPS of ``aa'' is ``aa''.

      3. If $j>2$ and $W[1] = W[j]$ (beginning and end letters match), then $V[1] = W[1] = V[k] = W[j]$ and $k>2$. 
      Furthermore, a LPS of $W[2 \dots j-1]$ is $V[2\dots k-1]$. In other words, we can compute a LPS of the 
      $W[2 \dots j-1]$ and then append $W[1]$ and $W[j]$ to the front and end to form a LPS of $W[1\dots j]$.

      4. If $j>2$ and $W[1] \neq W[j]$, then $V[1\dots k]$ will be the longer of the LPSes of $W[2\dots j]$ and $W[1\dots j-1]$.

      This is an optimal substructure because a LPS for an arbitrary string contains within it a LPS of a subsequence.

      {\bf Appropriate Notation}

      Let $C[i, j]$ denote the length of the LPS of the sequence $W[i\dots j]$.

      {\bf Recurrence with base cases}

      Our objective function, then, is:
      \begin{displaymath}
        C[i,j] = \left\{
          \begin{array}{lr}
            0  &   \text{ if $i > j$}\\
            1  &   \text{ if $i == j$ }\\
            2 + C[i+1, j-1]  &  \text{ if $W[i] == W[j]$}\\
            \text{max($C[i+1,j], C[i,j-1]$)}  &  \text{ if $W[i] \neq W[j]$ }
          \end{array}
          \right.
        \end{displaymath} 


      {\bf Pseudocode: Optimal Value of Objective Function}

      {\it Overview:}

      The algorithm takes in a string in the form of an array of length $m$ (not zero-indexed). 
      The $C[1\dots m, 1\dots m]$ table defines cells with the length of the LPS, filled left to right.
      The $b[1\dots m, 1\dots m]$ table shows an arrow pointing to the optimal subproblem solution. For instance, 
      $d[i, j]$ has an arrow pointing to the solution used to fill in $C[i, j]$.


      \begin{algorithmic}[1]
        \Function{calcPalindrome}{$m$, $W[1\dots m]$}


          \ForAll{$i=1$ to $m - 1$}
            \Comment{Loop to $m-1$ to handle the edge case of $m$}
            \State $C[i,i] = 1$
            \State $k = i + 1$

            \If{$W[i] == W[k]$}
              \State $C[i,k] = 2$
              \State $d[i,k] = "\swarrow"$
            \Else
              \State $C[i,k] = 1$
              \State $d[i,k] = "\leftarrow"$
            \EndIf
          \EndFor

          \Comment{Edge Case}
          \State $C[m,m] = 1$
          \ForAll{$i = m-2$ to $1$}
            \ForAll{$j = i + 2$ to $m$}
              \If{$W[i] == W[j]$}
                \State $C[i,j] = 2+ C[i+1, j-1]$ 
                \State $d[i,k] = "\swarrow"$
              \ElsIf{$C[i+1,j] \geq C[i, j-1]$}
                \State $C[i,j] = C[i+1, j]$ 
                \State $d[i,k] = "\downarrow"$
              \ElsIf{$C[i+1,j] \leq C[i, j-1]$}
                \State $C[i,j] = C[i, j-1]$ 
                \State $d[i,k] = "\leftarrow"$
              \EndIf
            \EndFor
          \EndFor
          \State return $C$, $d$
        \EndFunction
      \end{algorithmic}

      {\it Time and Space Complexity:}
      The two $for$ loops on line (14) and (15) make the algorithm look through $m$ columns and $m$ rows (ignoring constants) to 
      deduce the corner of $C[1,m]$.
      Thus, the running time is $\Theta(m^2)$.

      The space complexity is $\Theta(m^2)$ because two $m$ by $m$ matrices are needed. 


      {\bf Pseudocode: Optimal Solution}

      {\it Overview:}

      We start at $d[1, m]$ and trace back through by following the arrows computed in $calcPalindrome$.
      In the following $printLPS$, $i$ is the first index and $j$ is the second index for table $d$. 

      We assume that the ``.'' (period) indicates a concatenation of strings like in PHP. 

      Initially, call $printLPS$($1, m, d, W, subsequence$).

      \begin{algorithmic}[1]
        \Function{printLPS}{$i$, $j$, $d$, $W[1\dots m]$, $subsequence$}
          \If{$i>j$}
            \State return $subsequence$
          \ElsIf{$i == j$}
            \State return $subsequence$ . $W[j]$
          \ElsIf{$d[i,j] == "\downarrow"$}
            \State return $printLPS(i+1, j, d, W, subsequence)$
          \ElsIf{$d[i,j] == "\swarrow"$}
            \State return $W[i]$ . $printLPS(i+1, j-1, d, W, subsequence)$ . $W[j]$
          \ElsIf{$d[i,j] == "\leftarrow"$}
            \State return $printLPS(i, j-1, d, W, subsequence)$
          \EndIf
        \EndFunction
      \end{algorithmic}

      {\it Time and Space Complexity:}
      The algorithm can run through at most $m$ rows and $m$ columns. Thus, it runs $\Theta(m)$.

      No additional space complexity is added because $C$ and $d$ were already defined by the $calcPalindrome$ function. 

      Thus the entire algorithm's ($calcPalindrome$ and $printLPS$) space complexity is still $\Theta(m^2)$.

    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    % Question 7 
    %&=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& &=& =
    \bigskip
    \setcounter{equation}{0}
    \item 

      {\bf Optimal Substructure}

      For an employee $x$, let $x.rating$ denote the real conviviality rating of employee $x$ as given in the tree $T$. 

      Either employee $x$ is invited or not. Then, there are two cases to maximize the conviviality: 

      1. $x$ is not invited. Optimally select employees $y$ from the $x$'s subtree that maximizes conviviality (both direct and indirect subordinates. 
      Indirect meaning that $x$ is not necessarily $y$'s direct boss).
      
      2. $x$ is invited. To maximize conviviality, optimally select employees, including $x$, from the subtrees (direct and indirect subordinates) of each $x$'s children
      $w$ such that $w$ isn't invited.


      {\bf Appropriate Notation}

      Let $child(x)$ return the set of $x$'s {\it direct} children. 

      Let $x.leftchild$ return the left child of $x$ in the given company hierarchy tree $T$.

      Let $x.name$ return the name of the employee of node $x$ as represented in $T$.

      Let $x.rightsibling$ return the right sibling of $x$ in the given company hierarchy tree $T$.

      Let $Incl[x]$ denote the max possible sum of conviviality ratings from $x$'s subtree given that $x$ is invited. This is equivalent to \#2 in the optimal substructure
      stated above. 

      Let $Excl[x]$ denote the max possible sum of conviviality ratings from $x$'s subtree given that $x$ is not invited. This is equivalent to \#1 in the optimal substructure
      stated above. 

      {\bf Recurrence with base cases}

      Using this notation, translating the optimal substructure, our objective function to maximize conviviality is:


      \begin{displaymath}
        Incl[x] = \left\{
          \begin{array}{lr}
            x.rating & \text{ if $child(x) = \emptyset$ }\\
            x.rating + \sum_{y \in child(x)} Excl(y)  & \text{ otherwise }
          \end{array}
          \right.
        \end{displaymath} 

      \begin{displaymath}
      Excl[x] = \left\{
        \begin{array}{lr}
          0 & \text{ if $child(x) = \emptyset$ }\\
          \sum_{y \in child(x)} max( Incl[y], Excl[y])   & \text{ otherwise }
        \end{array}
        \right.
      \end{displaymath} 


      {\bf Pseudocode: Optimal Value of Objective Function}

      {\it Overview:}

      Call $compute(pres)$ will update the Incl and Excl arrays for all employees under $pres$. 
      Then using $max(Incl[pres], Excl[pres])$, it will return the max conviviality rating possible for the hierarchy subtree under the president.

      In other words, it returns the optimal value of the objective function under any arbitrary employee $x$.

      \begin{algorithmic}[1]
        \Function{compute}{$x$, $Incl$, $Excl$}
          \State $Incl[x] = x.rating$
          \State $Excl[x] = 0$

          \State $c = x.leftchild$

          \While{$c$ != null}
            \State $compute(c, Incl, Excl)$
            \State $Incl[x] += Excl[c]$
            \State $Excl[x] += max(Incl[c], Excl[c])$
            \State $c = c.rightsibling$
          \EndWhile

          \State return($max(Incl[x], Excl[x])$)
        \EndFunction
      \end{algorithmic}

      {\it Time and Space Complexity:}

      In the hierarchy tree with $V$ vertices, the time complexity is $\Theta(V)$ because the algorithm employs
      a single recursive traversal of the tree. 

      The space complexity is $\Theta(V)$ because the $Incl$ and $Excl$ arrays have a position for each vertex (employee).


      {\bf Pseudocode: Optimal Solution}

      {\it Overview:}
      $x$ is an arbitrary employee. We treat $x$ as the source node. 

      $b$ is a boolean that can either be $0$ or $1$. $printInv(x, 0)$ means that $x$ prints
      the best list possible that maximizes conviviality under the constraint that $x$ is excluded. 
      
      $printInv(x, 1)$ means print the best list possible (whether or not $x$ is excluded is of no consequence).

      We use the $Incl$ and $Excl$ arrays as before and can call $printInv(root, 1)$ to initialize. 

      \begin{algorithmic}[1]
        \Function{printInv}{$x$, $b$}
          \If{$b == 1$}
            \If{$Incl[x] > Excl[x]$}
              \State print $x.name$
              \State $b' = 0$
            \Else
              \State $b' = 1$
            \EndIf
          \Else
            \State $b' == 1$
          \EndIf

          \State $c = x.leftchild$
          \While{$c$ != $null$}
            \State $printInv(c, b')$
            \State $c = c.rightsibling$
          \EndWhile
        \EndFunction
      \end{algorithmic}

      {\it Time and Space Complexity:}

      The time complexity is $\Theta(V)$ because the method $printInv$ is called on every node in tree $T(V,E)$ with a 0 or 1.

      In the $printInv$ function, we do not take any more space because the $Incl$ and $Excl$ arrays are already defined. 
      Thus, the entire algorithm ($printInv$ and $compute$)'s space complexity is still $\Theta(V)$.


  \end{enumerate}

  
















































  

\end{document}


